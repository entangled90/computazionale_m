\input{header.tex}

\begin{document}

\input{title.tex}
\tableofcontents 
\newpage
\section*{Prefazione}
I programmi e gli algoritmi sono stati implementati seguendo le note del corso. Molti dettagli ampiamente discussi nelle note riguardo l'effettiva implementazione degli algoritmi sono stati tralasciati nella stesura di questa relazione.\\
I programmi che simulano gli algoritmi sono stati implementati interamente in linguaggio C e includono una prima analisi dei dati come il \emph{binning} e il calcolo di $\Delta r^2$ nei programmi di dinamica molecolare.\\
Sono stati scritti molti script in \emph{python} per operazioni in cui la velocità di esecuzione non era importante, tra cui script per mandare in esecuzione copie di un programma sui vari core, programmi per calcolare medie ed errori su dati provenienti da diverse run dei programmi, programmi per effettuare i fit e infine per fare grafici dei dati.\\
È stato scelto \emph{python} in quanto è un linguaggio di alto livello che ha permesso di svolgere questi task molto rapidamente, soprattutto in quanto sono state utilizzate queste librerie \emph{opensource}, tra cui:
\begin{itemize}
\item scipy: insieme di moduli che permette di usare \emph{python} in maniera simile a MatLab, usato principalmente per effettuare i fit
\item matplotlib: insieme di moduli usati per fare grafici 
\item numpy: insieme di moduli che permettono di velocizzare moltissimo le operazioni vettoriali e includono utili funzioni di statistica.
\end{itemize}
Per poter eseguire gli script in python è necessario avere queste librerie installate con una versione di \emph{python} superiore alla 3.0 .


\chapter{Sfere rigide}

\section{2 Dimensioni}

\subsection{Inizializzazione}
Il sistema è stato inizializzato su un reticolo rettangolare centrato.
Per ottenere la massima frazione di impacchettamento possibile con questo reticolo è necessario utilizzare un numero di particelle $n$ tale che $ n = 2k^2$, con $k$ intero.\\
Il lato della scatola $L$ \footnote{Si utilizzano unità adimensionate per l'espressione delle grandezze misurate, per la conversione in unità fisiche si rimanda alla formule sulle note} è stato fissato pari a 1.
Per questo motivo è stato utilizzato come numero di particelle in tutte le simulazioni pari a $128$.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{sfere2D/reticolo.png}
	\caption{Disposizione iniziale dei dischi, $n=128$}
\end{figure}
Il reticolo che viene generato dipende solo dal numero di particelle utilizzate, la frazione di impacchettamento $\eta$ influisce solo sul diametro $\sigma$ dei dischi. Esso è dato da:
$$
	\sigma = \sqrt{\frac{4 \eta}{ \pi n}}
$$
La frazione di impacchettamento massima con questo reticolo è facilmente calcolabile, notando che ci sono due dischi per ogni cella reticolare (di lato $l$) :
$$
	\eta_max = \frac{ 2 A_{disco}}{A_{cella}} = \frac{2 \pi r_{max}^2}{l^2} = \frac{2 \pi (\sqrt{2} \frac{l}{4})^2}{l^2} = \frac{\pi}{4} = 0.7853982..
$$
Infine, si utilizzano condizioni di periodicità sui bordi della scatola in modi che il sistema abbia invarianza traslazionale.\\
Le velocità vengono inizializzate inizialmente in modo pseudocasuale con una distribuzione di velocità piatta compresa fra $[-1,1]$ e in seguito si impone che la velocità del centro di massa sia nulla.\\
Inoltre, si fissa la temperatura a 1, che equivale a fissare l'energia cinetica del sistema.
Questa è anche l'unica scala di energia del sistema, in quanto non c'è una scala di energia potenziale (esso vale $0$ o $\infty$).\\
La raccolta dati è stata effettuata per una durata di 15 unità di tempo\footnote{In unità di misura adimensionali} . Ciò significa che il numero di collisioni effettuate non è costante, ma cresce con la frazione di impacchettamento, siccome diminuisce il tempo di collisione medio:
\begin{center}

\begin{tabular}{c c}
\toprule
	$\eta$ & Numero collisioni \\
	\midrule
	0.2 & $\sim$ 27500 \\
	0.34 & $\sim$ 50000 \\
	0.56 & $\sim$ 123500 \\
	0.66 & $\sim$ 211000 \\
	0.75 & $\sim$ 335000 \\
	\bottomrule
\end{tabular}
\end{center}

\subsection{Termalizzazione}
Il sistema viene fatto termalizzare per 10000 collisioni prima di prendere dati.
Si è verificato che il sistema avesse termalizzato dopo questo numero di collisioni studiando la distribuzione di probabilità del modulo della velocità.\\
\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.5]{sfere2D/boltzmann.png}
\end{figure}

Per fare ciò si è fatto partire il programma 400 volte, inizializzando il sistema sempre alla stessa temperatura e si è fatto un istogramma delle velocità calcolate dopo il ciclo di termalizzazione.
Si è poi fatto un fit con la distribuzione di Boltzmann in 2 dimensioni che è della forma:
$$
	P(|v|) = \frac{m}{k T} |v| e^{ - \frac{|v|^2}{2 k T}} = \frac{1}{T} |v| e^{ - \frac{|v|^2}{2T}}
$$
dove l'ultima uguaglianza vale per le unità di misura adimensionate che abbiamo utilizzato.\\
Il fit è stato fatto con la temperatura come unico parametro libero e concorda con la temperatura a cui è stato inizializzato il sistema:
$$
	T_{fit} = 1.003 \pm 0.002
$$


\subsection{Pressione}
Si analizza ora la pressione in funzione della frazione di impacchettamento.\\
Si è rappresentata la seguente osservabile, calcolata attraverso la formula\footnote{Utilizzata in unità di misura adimensionate: $V=1$,$k=1$,$m=1$}
\begin{center}
$$
	\frac{P V_0}{n k_{b} T} \, =\,  \frac{PV}{nT}\frac{\eta}{\eta_0} \, = 1 + \frac{m \sigma}{3 K_{en} t_{tot}} \sum_{coll} | \Delta v_{ij}| 
$$
\end{center}


Gli errori sono stato calcolati facendo girare dieci volte il programma agli stessi valori della frazione di impacchettamento e assegnando come errore la deviazione standard della media di questo campione di misure.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/pression.png}
	\caption{ $\frac{P V_0}{n k_{b} T}$ in funzione di $\eta$ con $n=128$ particelle}
	\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/pressionzoom.png}
	\caption{Ingradimento di $\frac{P V_0}{n k_{b} T}$ in funzione di $\eta$ con $n=128$ particelle}
	\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/pressionzoomzoom.png}
	\caption{Ulteriore ingrandimento di  $\frac{P V_0}{n k_{b} T}$ in funzione di $\eta$ con $n=128$ particelle}
	\end{figure}





Si può vedere dal grafico che questo sistema presenta una transizione di fase dovuta all'alta densità di impacchettamento.\\
La transizione inizia ad un valor della frazione di impacchettamento leggermente inferiore a $\eta \sim 0.69$, ma è presente una regione metastabile in cui la pendenza della curva si riduce notevolmente rispetto alla regione a frazione d'impacchettamento minore..
Subito dopo questo valore la curva ricomincia a salire, anche se con pe	ndenza minore.
Per $\eta \sim 0.71$ la pendenza della curva torna ad essere piatta, mentre per $\eta \sim 0.71$ la curva ricomincia a salire, con una pendenza superiore rispetto a prima della transizione di fase.\\
Le due regioni in cui la pendenza della curva si annulla sono agli estremi della regione in cui avviene la transizione di fase.\\
Superata la transizione di fase la pressione sale con una pendenza maggiore rispetto alla fase \emph{liquida}, altro segno che la stato del sistema è cambiato.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% RIGUARDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Tempi di collisioni}

Come si è visto analizzando il numero di collisioni avvenute in funzione della frazione di impacchettamento, il tempo medio di collisione aumenta all'aumentare della frazione di impacchettamento.\\
Ciò è dovuto sostanzialmente al fatto che la distanza media tra il bordo dei dischi diminuisce all'aumentare del diametro e la distribuzione di velocità è pressochè simile al variare della frazione di impacchettamento.
Possiamo osservare questo comportamento sia analizzando il tempo di collisione medio tra i dischi sia studiando la distribuzione di probabilità associata ai tempi di collisione.\\

\subsubsection*{Tempo medio di collisione}
La quantità che è stata misurata è il tempo medio di collisione per particella. \'E stato calcolato usando la formula seguente:
$$
	t_{coll}  = \frac{t_{tot}}{2 N_{collisioni}} n_{particelle}
$$

Esso è stato calcolato per ogni simulazione e come nel caso della pressione, sono state ripetute 10 volte le misure. Da questo campione di dati si è calcolato media e deviazione standard della media.


\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/tc.png}
	\caption{Tempo medio di collisione in funzione della funzione di impacchettamento, $n=128$}
	\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/tczoom.png}
	\caption{Ingrandimento del tempo medio di collisione in funzione della funzione di impacchettamento, $n=128$}
	\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/tczoomzoom.png}
	\caption{Ulteriore ingrandimento del tempo medio di collisione in funzione della funzione di impacchettamento, $n=128$}
	\end{figure}



Come si può vedere dal grafico si ha una regione in cui la curva è quasi piatta a partire da un valore della frazione di impacchettamento poco sotto $\eta \sim 0.69$ fino a $\eta \sim 0.71$.\\
Questi sono gli stessi valori per cui si è notato un comportamento diverso della pressione nel grafico precedente.\\
Come si vedrà in seguito, questo intervallo di temperature caratterizzerà tutte le quantità che verranno analizzate.
 
\subsubsection{Distribuzione di probabilità tempi di collisione}
Oltre ad analizzare il valor medio del tempo di collisione per particella, si può studiare anche la sua distribuzione di probabilità durante ogni simulazione.\\
Analizzando gli istogrammi creati a partire dai tempi di collisione di ogni singolo urto si può vedere che la distribuzione di probabilità è della forma:
$$
	P(t) = \frac{1}{\tau} \, e^{-\frac{t}{\tau}} \qquad \mbox{Normalizzata}
$$ 
dove $\tau$ si dimostrerà essere proprio il tempo di collisione medio per particella.\\
Ci si aspetta dunque che la distribuzione di probabilità diventi sempre più piccata aumentando $\eta$ (in quanto $t_{coll}$ diminuisce all'aumentare di $\eta$).
Si veda il caso per qualche valore di $\eta$:
\begin{center}
	\begin{figure}[h]
	\centering
		\includegraphics[scale=0.5]{sfere2D/pdf_tc.png}
	\caption{Confronto tra distribuzioni di probabilità per il tempo di collisione per particella a vari $\eta$}
	\end{figure}
\end{center}

Si veda inoltre il risultato del fit di uno di questi istogrammi con la distribuzione di probabilità citata sopra:

\begin{center}
	\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.5]{sfere2D/fit_pdf_tc.png}
		\caption{Fit della distribuzione di probabilità con $e^{-\frac{t}{\tau}}$.}
	\end{figure}
\end{center}
Ci aspetta che il valore di $\tau$ ottenuto tramite questo fit coincida con il valor medio del tempo di collisione per particella calcolato durante l'esecuzione del programma. Si può capire ciò da questo semplice fatto:
$$
	<t> \, = \, \frac{1}{\tau}\int_0^{\infty} t \, e^{-\frac{t}{\tau}}\,dt = \tau
$$
Ci si aspetta quindi che se la distribuzione di probabilità è di quella forma allora il risultato del fit deve coincidere con il valor medio del tempo di collisione.\\
Nel grafico seguente si sono sovrapposti i valori di $t_{coll}$ calcolato come valor medio del tempo di collisione per particella e il valore di $\tau$ calcolati attraverso il fit:
\begin{center}
	\begin{figure}[h!]
		\centering
		\subfigure[Andamento generale]{
		\includegraphics[scale=0.5]{sfere2D/tau_tcoll.png}
		}
		\subfigure[Ingradimento zona di transizione]{
		\includegraphics[scale=0.5]{sfere2D/tau_tcollzoom.png}
		}
	\caption{Confronto tra $t_{coll}$ e $\tau$}
	\end{figure}
\end{center}
Nel grafico non sono stati inseriti gli errori in quanto non sono stati calcolati gli errori associati agli istogrammi e quindi l'errore restituito dal fit non è del tutto significativo.\\
Si può vedere come l'accordo tra i due metodi di calcolo sia eccellente, anche nella regione di transizione di fase.
Ciò è segno del fatto che la distribuzione di probabilità mantenga sempre la forma $e^{-\frac{t}{\tau}}$ .




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Libero cammino medio}
Il valore del libero cammino è stato calcolato mediando il libero cammino medio per particella fra tutte le particelle. Sono state eseguite 10 simulazioni come per le altre quantità e gli errori stato calcolati sulla base di questo campione.\\

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/mfp.png}
	\caption{Libero cammino medio in funzione di $\eta$}
	\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/mfpzoom.png}
	\caption{Ingrandimento del libero cammino medio in funzione di $\eta$}
	\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.48]{sfere2D/mfpzoomzoom.png}
	\caption{Ulteriore ingrandimento del ibero cammino medio in funzione di $\eta$}
	\end{figure}

Si vede un comportamento del tutto simile a quanto accade con il tempo medio di collisione per particella, con una zona di transizione di fase nello stesso range di $\eta$ delle altre quantità.


\newpage
\subsection{Spostamento quadratico medio in funzione del tempo}
Il valore di $\Delta r^2(t)$ è stato calcolato per ogni singola particella, sfruttando l'invarianza temporale del sistema, mediando così tra tutti gli istanti distanti tra loro un tempo $t$. 
Il grafico è stato generato a partire da 5 simulazioni indipendenti per ogni valore della temperatura. Si è calcolato il valor medio e l'errore a partire da questo insieme di dati per ogni istante temporale.\\
Il sistema è stato simulato fino a un valore del tempo pari a 15, ma i valori di $\Delta r^2(t)$ per $t$ superiore a 10 sono stati scartati in quando tendevano ad oscillare in quanto per essi il campione di dati era minore.\\
Si è calcolata questa quantità ad istanti di tempo discreti pari a 0.03 e per fare ciò è stato necessario spezzare l'evoluzione temporale in modo da prendere dati per valori multipli di 0.03.\\
Il valore aspettato per un sistema disordinato, prima della transizione di fase, è calcolabile teoricamente assumendo che in un tempo abbastanza grande ogni particella abbia avuto l'oppportunità di spostarsi in tutta la scatola. Esso è calcolabile in questo modo:
$$
<\Delta r^2(t)> \overset{\mathit{t\rightarrow \infty}}{\simeq} \int_{-\frac{L}{2}}^{\frac{L}{2}} dx \int_{-\frac{L}{2}}^{\frac{L}{2}}dy \, (x^2 + y^2 )= \frac{L^2}{6} \overset{\mathit{L=1}}{=} 0.166667..
$$
\begin{center}
	\begin{figure}[h]
	\centering
		\includegraphics[scale=0.5]{sfere2D/dr2vari.png}
	\caption{Confronto tra i $\Delta r^2(t)$ a vari valori di $\eta$}
	\end{figure}
\end{center}
Come si può vedere dal grafico, per valori di $\eta$ non troppo vicini alla regione di transizione la curva arriva al valore teorico calcolato prima e poi si appiattisce. All'aumentare di $\eta$ la forma della curva cambia e diventa una retta in prima approssimazione, con una pendenza che decresce sempre più all'aumentare della frazione di impacchettamento. Questo comportamento è segno della scarsa mobilità dei dischi all'aumentare del loro diametro (ossia di $\eta$).
Per veder meglio questo fatto, si consideri il seguente grafico:
\begin{center}
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.5]{sfere2D/dr2trans2.png}
	\end{figure}
\end{center}
Come si può vedere, prima della transizione di fase ($\eta=0.6$) il sistema arriva rapidamente al valore teorico e continua ad oscillare intorno a quel valore.
Per i valori successivi alla transizione di fase, le curve continuano ad avere una pendenza sempre minore.
\begin{myfig}[ht]
	\includegraphics[scale=0.5]{sfere2D/dr2cfr.png}
\caption{Confronto di $\Delta r^2$ fino a $t=250$ dopo la transizione di fase}
\end{myfig}
Aumentando il tempo della simulazione fino a $t=300$ si è visto che l'andamento di $\Delta r^2$ si mantiene lineare per tutto il tempo della simulazione, anche se sembra che la pendenza delle curve diminuisca leggermente.

\newpage
\clearpage
\section{3 Dimensioni}

\subsection{Inizializzazione}
L'inizializzazione dell'algoritmo avviene in maniera del tutto simile a quanto fatto con i dischi in 2 dimensioni.
In questo caso, il reticolo in cui vengono inizializzate le particelle è un reticolo BCC. Per questo reticolo la cella elementare contiene 2 particelle.\\
\begin{center}
	\begin{figure}[h]
	\centering
		\includegraphics[scale=0.6]{sfere3D/reticolo.png}
	\end{figure}
\end{center}
La frazione di impacchettamento massima raggiungibile in questo caso è data da:
$$
	\eta_{max} = 2 \frac{V_{sfera}}{V_{cella}} = 2 \frac{ \frac{4}{3} \pi r_{max}^3}{ l^3 } = 2 \frac{\frac{4}{3} \pi
	( \frac{l \sqrt{3}}{4} )^3}{l^3 }= 0.6801747616....
$$
Le velocità sono state inizializzate come nel caso bidimensionale e la temperatura è stata fissata al valore $\frac{2}{3}$.


\subsection{Termalizzazione}
Il numero di collisioni utilizzate per la termalizzazione del sistema è stato di 20000.\\
Come per le sfere in 2 dimensioni si è valutata la corretta termalizzazione del sistema analizzando la distribuzione di probabilità per il modulo della velocità e facendo un fit con la Maxwell-Boltzmann in 3 dimensioni.
In 3 dimensioni la distribuzione di probabilità assume la forma:
$$
	P(|v|) \, = \, 4 \pi \left(\frac{m}{2 \pi k_{b} T}\right)^{\frac{3}{2}} |v|^2 e^{-\frac{m |v|^2}{2 k_b T}}
$$
%%%%%%%%%MAX_BOLTZMANN!!
Per la creazione dell'istogramma sono state eseguite circa 150 simulazioni.
\begin{myfig}
	\includegraphics[scale=0.5]{sfere3D/boltzmann.png}
	\caption{Confronto tra Maxwell-Boltzmann e la distribuzione di probabilità per la velocità}
\end{myfig}
La temperatura restituita dal fit è:
$$
	T = 0.669 \pm 0.05
$$
in pieno accordo con la temperatura a cui è stato inizializzato il sistema.



\subsection{Pressione}
Il calcolo della pressione è del tutto analogo al caso bidimensionale con l'unica differenza data dalla relazione tra energia e temperatura in 2 dimensioni e 3 dimensioni. I valori medi e gli errori sono stati calcolati con lo stesso metodo.\\
L'andamento della pressione in funzione di $\eta$ è simile al caso bidimensionale al di fuori della zona di transizione, mentre in quella regione, la curva ha un comportamento molto diverso.
\begin{myfig}[h]
	\includegraphics[scale=0.5]{sfere3D/pressione.png}
	\caption{Grafico relativo alla pressione per $n=128$ sfere.}
\end{myfig}
\begin{myfig}[h]
	\includegraphics[scale=0.5]{sfere3D/pressionezoomzoom.png}
	\caption{Particolare della transizione di fase del grafico relativo alla pressione per $n=128$ sfere.}
\end{myfig}

Si può vedere dal grafico ($n=128$) che per un valore di $\eta$ compreso tra 0.4935 e 0.4943 si ha un aumento dell'errore pari a un fattore 5. Ciò indica che si è all'inizio della transizione di fase.
Il valore della pressione cresce ancora fino a $\eta = 0.498$.
Sopra questo valore di $\eta$ la pressione comincia a scender ma gli errori diventano molto più grandi, segno delle grandi fluttuazioni presenti nel sistema, tipiche di una transizione di fase.
Al valore $\eta \sim 0.51$ la pressione torna a risalire e con errori paragonabili a prima della transizione di fase.\\
Infine si veda il confronto tra grafici della pressione per $n=128$ e $n=250$:

\begin{myfig}[h]
	\subfigure[$n=128$]{
		\includegraphics[scale=0.35]{sfere3D/pressionezoomzoom.png}
	}
	\subfigure[$n=128$]{
		\includegraphics[scale=0.35]{sfere3D/pre250.png}
	}
	\caption{Confronto della zona di transizione di fase per $n=128$ e $n=250$}
\end{myfig}
Nonostante il numero di sfere sia quasi raddoppiato, la curva mantiene lo stesso andamento e anche il valore di $\eta$ per cui si ha la transizione di fase sono del tutto simili. 


\subsection{Spostamento quadratico medio}
Come per la pressione, anche lo spostamento quadratico medio è stato calcolato in maniera uguale a quanto fatto in 2 dimensioni. Chiaramente, il valore limite che ci possiamo aspettare per $\eta$ piccoli è diverso:
$$
<\Delta r^2(t)> \overset{\mathit{t\rightarrow \infty}}{\simeq} \int_{-\frac{L}{2}}^{\frac{L}{2}} dx \int_{-\frac{L}{2}}^{\frac{L}{2}}dy \int_{-\frac{L}{2}}^{\frac{L}{2}} dz \, ( x^2 + y^2 +z^2 ) = \frac{L^2}{4} \overset{\mathit{L=1}}{=} 0.25
$$
Il comportamento del sistema è analogo a quello bidimensionale, come si può vedere da questo grafico:

\begin{myfig}[h]
	\includegraphics[scale=0.5]{sfere3D/dr2vari.png}
	\caption{Spostamento quadratico medio a vari $\eta$}
\end{myfig}
Come si può vedere dal grafico, c'è una netta differenza tra i grafici prima della solidificazione e dopo.\\
Infatti il sistema per $\eta=0.5$ è nella zona di transizione, prima che il solidifichi e si può vedere come la curva abbia ancora un comportamento simile a quello in fase liquida.
Diventa completamente diverso, invece, per il valore $\eta=0.51$, che come si è visto dal grafico della pressione è il valore per cui il sistema inizia ad entrare in fase solida.

\begin{myfig}[h]
\includegraphics[scale=0.5]{sfere3D/dr2trans.png}
\caption{$\Delta r^2$ per valori di $\eta$ vicini alla transizione}
\end{myfig}

\subsection{Limite termodinamico}
Si studia ora l'estrapolazione al limite termodinamico della pressione. Il limite termodinamico viene effettuato aumentando il numero di particelle del sistema e il volume, in modo tale che il loro rapporto rimanga costante. Il limite termodinamico viene raggiunto mandando $N,V \rightarrow \infty$
Si veda ora il confronto tra i valori di $\frac{P V}{n k_b T} -1$ per $\eta=0.3$ con numero di particelle compreso fra 32 e 512.\\
La raccolta dati è stata ripetuta 9 volte per ogni $n$ e si è calcolato valor medio ed errore sulla base di questo campione. I risultati sono i seguenti:
\begin{center}
	\begin{tabular}{c c c c}
	\toprule
	$N$ & $\frac{1}{N}$ & $<\frac{P V}{n k_b T} -1> $ & Errore \\
	\midrule
	$32	$	& $0.031250$	&$ 6.06	$	& $0.03 $\\
	$64	$	& $0.015625$	&$ 6.01	$	& $0.01 $\\
	$128$	& $0.007812$	&$ 5.989$	& $ 0.002 $\\
	$256$	& $0.003906$	&$ 5.981$	& $ 0.004$ \\
	$512$	& $0.001953$	&$ 5.973$	& $ 0.003$ \\
	\bottomrule
	\end{tabular}
\end{center}


\begin{myfig}[h]
	\includegraphics[scale=0.58]{sfere3D/lim_therm.png}
	\caption{Andamento della pressione al limite termodinamico}
\end{myfig}
Il fit è stato effettuato con una retta di equazione $y=mx +q$ e il grafico è stato disegnato in funzione di $\frac{1}{N}$
	Il risultato del fit da come risultato:
\begin{align}
	m &= 2.8 \pm 0.02\\	
	q &= 5.968 \pm 0.001\\
\end{align}
Estrapolando il valore per $N \rightarrow \infty$ il valore è dato dal termine noto della retta e ottienamo quindi il valore:
$$
	\frac{P V}{n k_b T} -1 = 5.968 \pm 0.001 \qquad \mbox{per} \quad N \rightarrow \infty
$$



\chapter{Sfere soffici}
\section{Inizializzazione e definizione dei parametri}
Il sistema è costituito da un numero $N$ di particelle in una scatola di lato $L$ con condizioni periodiche al bordo. A differenza delle sfere rigide, non c'è una lunghezza caratteristica essendo trattate come puntiformi. Per questo motivo si è scelto come unità di lunghezza la scala $\sigma$ che entra nella definizione del potenziale di Lennard-Jones:
$$
	U(r) = 4 \, \epsilon \left[ \left(\frac{\sigma}{r}\right)^{12} - \left(\frac{\sigma}{r}\right)^6 \right]
$$
Inoltre, come scala di energia è stata utilizzato $\epsilon$.\\
Si è scelto di porre queste due grandezze a 1 per comodità e per velocizzare il calcolo del potenziale durante l'algoritmo. Per via di questa scelta, il lato della scatola non è più uguale a 1 ovviamente, ma viene calcolato a partire dalla densità e dal numero di particelle in questo modo:
$$
	L = \sqrt[3]{\frac{\rho}{N}}
$$
Infine, le masse delle particelle e la costante $k_b$ sono state poste a 1.\\
Il sistema è stato inizializzato su un reticolo cubico semplice, inizializzando inizialmente le particelle con una distribuzione di probabilità piatta compresa fra $[-1,1]$.
In seguito sono stati fissati i parametri \emph{fisici} del sistema come la temperatura o l'energia totale del sistema a seconda delle richieste dell'esercizio utilizzando il metodo indicato sulle note.\\
L'algoritmo implementato utilizza le liste dei vicini come indicato sulle note che vengono aggiornate ogni 10 step evolutivi.\\
Per l'evoluzione del sistema è stato utilizzato l'algoritmo \emph{velocity verlet} con uno step temporale pari $\delta t = 0.001$ e si è potuto vedere che grandezza come l'energia totale e il momento vengono conservate (nel senso che dopo circa 10000 step evolutivi la loro variazione è di circa $10^{-6} - 10^{-7}$ come si vedrà dai grafici).

\subsection{Termalizzazione}
Per stimare il tempo necessario di termalizzazione si è valutato l'andamento dell'energia e della temperatura. Durante questo periodo di termalizzazione si è fissato il valore della temperatura alla temperatura desiderata.

\begin{myfig}[h]
	\subfigure[$N=108$ particelle]{
		\includegraphics[scale=0.4]{soft_core/temp_therm.png}
	}
	\subfigure[$N=500$ particelle]{
		\includegraphics[scale=0.4]{soft_core/temp_therm500.png}
	}
	\caption{Temperatura in funzione del tempo in fase di termalizzazione per diverso numero di particelle}
\end{myfig}

\begin{myfig}[h]
	\subfigure[$N=108$ particelle]{
		\includegraphics[scale=0.4]{soft_core/en_therm.png}
	}
	\subfigure[$N=500$ particelle]{
		\includegraphics[scale=0.4]{soft_core/en_therm500.png}
	}
	\caption{Energia in funzione del tempo in fase di termalizzazione per diverso numero di particelle}
\end{myfig}
Come si può vedere dai grafici, il sistema non impiega molto a termalizzare, già dopo 2 unità di tempo si può dire che il sistema ha ormai termalizzato.
Nelle simulazioni si è deciso di utilizzare un tempo di termalizzazione pari a 5 o 10 ossia 5000 o 10000 step di evoluzione.\\
Si può vedere dai grafici, inoltre come le fluttuazioni di entrambe le osservabili diminuiscano all'aumentare del numero di particelle.
Dopo aver fatto termalizzare il sistema il valore di temperatura o energia totale è stato lasciato libero nella simulazione senza più esser fissato al valore voluto ad ogni step.\\

\section{Produzione e analisi dati}
La raccolta e l'analisi dei dati viene divisa nelle 4 richieste delle note
\subsection{Esercizio 9}
In questa prima raccolta dati prevede le seguenti condizioni iniziali:
$$
	\rho = 0.7 \qquad <T>=1.19 \qquad N=108,\,500
$$
Si veda ora il confronto fra l'energia interna del sistema fra $N=108$ e $N=500$ particelle con queste condizioni iniziali.
Il numero di step in cui sono stati raccolti dati è stato 20000.L'errore è stato calcolato attraverso il \emph{binning} con intervalli contenenti 2000 dati.
\begin{myfig}[h]
	\subfigure[$N=108$ particelle]{
		\includegraphics[scale=0.35]{soft_core/9_int108.png}
	}
	\subfigure[$N=500$ particelle]{
		\includegraphics[scale=0.35]{soft_core/9_int500.png}
	}
	\caption{Andamento dell'energia interna per particella con diverso numero di particelle}
\end{myfig}

\begin{myfig}[h]
	\includegraphics[scale=0.5]{soft_core/9cfr.png}
	\caption{Confronto tra $N=108$ e $N=500$}
\end{myfig}
\begin{align}
N=108 \qquad <\frac{U}{N \epsilon}> &= -3.520 \pm 0.004 \\
N=500 \qquad <\frac{U}{N \epsilon}> &= -3.503 \pm 0.001 \\
\end{align}
Come si può vedere dalla sovrapposizione dei due grafici, aumentando il numero di particelle le fluttuazioni sull'energia interna diminuiscono e quindi anche l'errore associato.
Questo fatto può essere visto come conseguenza dell'equivalenza dell'ensemble microcanonico con l'ensemble canonico al limite termodinamico.
Nel nostro caso, infatti, il nostro sistema è isolato e con energia totale costante. L'energia interna, invece è legata alle fluttuazioni della temperatura del sistema in quanto la temperatura è proporzionale all'energia cinetica.
L'equivalenza fra i due ensemble implica che al limite termodinamico il sistema simulato, è equivalente a un sistema immerso in un bagno termico a una temperatura fissata.\\
Ci aspetta quindi che le fluttuazioni sulla temperatura diminuiscano all'aumentare del numero di particelle e di conseguenza anche le fluttuazioni sull'energia interna.

%%%%%%%%%%%%%%CONTROLLA

\subsection{Esercizio 10}
Il sistema viene ora inizializzato con questi parametri:
$$
	\rho = 0.6 \qquad <T> = 1.22 \qquad N=108
$$
Il sistema è stato fatto evolvere per 40000 step temporali.\\
\subsubsection{Temperatura}
La prima quantità analizzata è l'andamento della temperatura nel tempo. Per la stima dell'errore si è usata la tecnica del \emph{binning} con intervalli contenenti 2500 dati.\\
Il valore ottenuto è il seguente:
$$
		<\frac{k_b T}{\epsilon}> = 1.175 \pm 0.002
$$

\begin{myfig}[h]
\includegraphics[scale=0.55]{soft_core/10_temp.png}
\caption{Andamento della temperatura}
\end{myfig}
Il valore medio della temperatura è diverso dal valore a cui si è inizializzato il sistema. Ciò è dovuto al fatto che questo sistema è isolato e quindi si conserva l'energia totale e non l'energia cinetica (che è proporzionale alla temperatura).
Come si è visto dal grafico della sezione precedente infatti, nemmeno l'energia interna è una costante del moto, quindi non può esserlo nemmeno la temperatura.\\

\subsubsection{Pressione}
Un'altra quantità misurata riguarda la pressione o meglio la correzione alla pressione del gas ideale dovuta al fatto che le particelle interagiscono fra loro.
Come per la temperatura, è stato usato il \emph{binning} con intervallo di 2500 dati ciascuno.\\
Il risultato è il seguente:
$$
	\frac{P}{\rho k_b T} - 1 = 0.119 \pm 0.009
$$ 

\begin{myfig}
\includegraphics[scale=0.55]{soft_core/10_pres.png}
\caption{Andamento di $\frac{P}{\rho k_b T} - 1$}
\end{myfig}

\subsubsection{Energia interna}
L'ultima osservabile considerata è l'andamento dell'energia interna, gli errori sono stati calcolati come nei casi precedenti

\begin{myfig}
\includegraphics[scale=0.55]{soft_core/10_U.png}
\caption{Andamento dell'energia interna}
\end{myfig}
$$
<\frac{U}{\epsilon N}> = -3.008 \pm 0.004
$$

\subsubsection{Confronto tra le osservabili}
Infine, si possono confrontare le varie osservabili in un unico grafico.
\begin{myfig}
\includegraphics[scale=0.55]{soft_core/10_cfr.png}
\caption{Confronto tra pressione, temperatura ed energia interna}
\end{myfig}
È interessante notare come temperatura ed energia interna oscillino nello stesso range.
Ci si poteva aspettare questo risultato in quanto l'energia totale è conservata dal sistema.
Siccome essa può essere scritta in questo modo:
$$
	E_{tot} = \frac{1}{N} (K + U) = \frac{3}{2} T+ \frac{U}{N} 
$$
Quindi le oscillazioni della temperatura devono essere minori di quelle sull'energia interna. Infatti, l'errore associato alla temperatura è minore rispetto all'errore sull'energia interna.


\subsection{Esercizio 11}
Il sistema è stato inizializzato con queste condizioni iniziali:
$$
	\rho = 0.9 \qquad N=256 \qquad <T> = 0.8,\, 1.087
$$
Si è interessati a confrontare l'andamento dello spostamento quadratico medio in funzione del tempo alle varie temperature. Il calcolo di $\Delta r^2(t)$ è stato effettuato in maniera del tutto analoga a quanto fatto per le sfere rigide in 3D, con l'unica differenza che ora il lato della scatola è diverso da 1 e quindi si è normalizzato il risultato dividento per $L^2$.
\begin{myfig}[h]
\includegraphics[scale=0.6]{soft_core/11_dr2.png}
\caption{Confronto di $\Delta r^2(t)$ a varie temperature}
\end{myfig}
Il grafico è stato generato a partire da 6 simulazioni indipendenti per ogni valore della temperatura. Si è calcolato il valor medio e l'errore a partire da questo insieme di dati per ogni istante temporale.
Si può vedere come abbassando la temperatura la rapidità con cui il valore dello spostamento quadratico medio diminuisce, in modo simile a quando accadeva nel caso delle sfere rigide.\\
Anche in questo caso il valore limite di questa quantità è $\Delta r^2(t \rightarrow \infty) = 0.25$ come nel caso delle sfere rigide in 3 dimensioni.\\
Il valore limite viene raggiunto (nel tempo in cui è stato simulato il sistema) solo nel caso di temperatura più alta. Si può vedere inoltre come la pendenza della curva a temperatura più bassa sia sempre minore della pendenza dell'altra curva.

\subsection{Esercizio 12}
L'ultima classe di simulazioni è stata inizializzata con i seguenti parametri:
$$
 \rho = 0.7 \qquad <\frac{E}{N \epsilon}> = -2.98 \qquad N = 100,150,250,500,800,1000
$$
Sono stati raccolti i dati di energia interna e temperatura per ogni simulazione. Ogni simulazione è stata ripetuta 5 volte per stimare in maniera corretta l'errore e il valor medio.\\
Infine è stato estrapolato il valore delle grandezze nel limite termodinamico, per una generica osservabile $O$, facendo un fit con una retta in funzione di $\frac{1}{N}$:
$$
	O(N) \, = \,A \frac{1}{N} + B
$$
in modo tale che il valore di $O(\infty) = B$.
\subsubsection{Energia interna}
I valori dell'energia interna in funzione del numero di particelle sono i seguenti:
\begin{center}
	\begin{tabular}{c c c }
		\toprule	
		$N$ & $ <\frac{U}{N \epsilon}>  $ Errore \\
		\midrule
100 &  -3.901 & 0.002 \\ 
150 &  -3.906 & 0.002 \\ 
250 &  -3.907 & 0.0014 \\ 
 500 &  -3.9123 & 0.0012 \\ 
 800 &  -3.913 & 0.003 \\ 
 1000 &  -3.9106 & 0.0015 \\ 
 
	\end{tabular}
\end{center}


I valori restituiti dal fit sono:
$$
	A =  1.2\pm 0.2 \qquad B = -3.913 \pm 0.001
$$
Il valore al limite termodinamico dell'energia interna è quindi:
$$
	<\frac{U_{LT}}{N \epsilon}> = -3.913 \pm 0.001
$$
\begin{myfig}[ht]
\includegraphics[scale=0.5]{soft_core/12lt.png}
\caption{Limite termodinamico per la densità di energia interna}
\end{myfig}


\subsubsection{Temperatura}
Per la temperatura è stata fatta una cosa analoga. I valori ottenuti ripetendo 5 simulazioni sono i seguenti:
\begin{center}
	\begin{tabular}{c c c }
		\toprule	
		$N$ & $<\frac{T}{\epsilon} $ Errore \\
		\midrule
		100 &  0.6141  & 0.0011 	\\
		150 &  0.6174  & 0.0012 	\\
		250 &  0.6177  & 0.0009 	\\
		500 &  0.6215  & 0.0008 	\\
		800 &  0.622  & 0.002 	\\
		1000 &  0.620  & 0.001 	\\
		\bottomrule
	\end{tabular}
\end{center}

Il risultato del fit è:
$$
	A = -0.81 \pm 0.14 \qquad B = 0.6223 \pm 0.0007
$$
Il valore della temperatura estrapolato al limite termodinamico è quindi:
$$
	T_{LT} = 0.6223 \pm 0.0007
$$
\begin{myfig}[h]
\includegraphics[scale=0.5]{soft_core/12lt_temp.png}
\caption{Limite termodinamico per la temperatura}
\end{myfig}



%%%%%%%% FIGURE E TABELLE 





\chapter{Modello di Ising}
Il modello è stato implementato su un reticolo bidimensione di larghezza N e inizializzando gli spin al valore $\pm 1 $  con uguale probabilità.
Sono stati implementati due algoritmi: Metropolis e Swendsen-Wang.\\

\section{Termalizzazione}
Possiamo valutare quando avviene la corretta termalizzazione del sistema analizzando l'andamento della magnetizzazione e dell'energia in funzione del tempo markoviano.
Di seguito è riportato l'andamento dell'energia e della magnetizzazione durante la termalizzazione a due diverse temperature.
\subsection*{Metropolis}
\begin{figure}[h]
\subfigure[$\beta=0.3$]{
\includegraphics[scale=0.45]{metropolis/en_therm.png}
}
\subfigure[$\beta=0.453$]{
\includegraphics[scale=0.45]{metropolis/en_therm_crit.png}
}
\caption{Energia (Metropolis)}
\end{figure}
\begin{figure}[h]
\subfigure[$\beta=0.3$]{

\includegraphics[scale=0.45]{metropolis/mag_therm.png}
}
\subfigure[$\beta=0.453$]{

\includegraphics[scale=0.45]{metropolis/mag_therm_crit.png}
}
\caption{Magnetizzazione  (Metropolis)}
\end{figure}
Come si può vedere dal grafico relativo alla magnetizzazione a $\beta=0.453$, vicino al punto critico il tempo di termalizzazione cresce di molto. Esso rimane comunque intorno a 100 alla temperatura critica.
Dopo l'analisi di questi dati si è deciso di fissare il tempo di termalizzazione a 1000 passi temporali.
\subsection*{Swendsen-Wang}
\begin{figure}[h]
\subfigure[$\beta=0.3$]{
	\includegraphics[scale=0.45]{sw/en_therm0-3.png}
}
\subfigure[$\beta=0.453$]{
\includegraphics[scale=0.45]{sw/en_therm0-43.png}
}
\caption{Energia (Swendsen-Wang) }
\end{figure}

\begin{figure}[h]
\subfigure[$\beta=0.3$]{
	\includegraphics[scale=0.45]{sw/mag_therm0-3.png}
	}
\subfigure[$\beta=0.453$]{
\includegraphics[scale=0.45]{sw/mag_therm0-43.png}
}
\caption{Magnetizzazione  (Swendsen-Wang)}
\end{figure}
Anche con questo algoritmo, il tempo di termalizzazione è molto minore dei 1000 passi utilizzati per far termalizzare il sistema nel programma.
La sostanziale differenza che si vede nei grafici relativi alla magnetizzazione vicino al punto critico è dovuta all'inefficienza dell'algoritmo Metropolis nell'estrarre configurazioni scorrelate vicino al punto critico, fenomeno solitamente chiamato \emph{critical slowing down}.
Esso si manifesterà più chiaramente nello studio dell'autocorrelazione delle configurazioni.


\section{Autocorrelazione fra le configurazioni}
Come in ogni simulazione Monte Carlo, è necessario studiare l'autocorrelazione delle configurazione estratte attraverso l'algoritmo in modo da stimare l'efficienza dell'algoritmo ad estrarre configurazioni
indipendenti e quindi nel produrre statistica.\\
Il tempo di autocorrelazione è stato calcolato utilizzando la formula:
$$
	\tau_{corr} = \frac{1}{2} + \sum_{t=1}^{t_{max}} \Gamma(t) \qquad \mbox{dove} \; \Gamma(t)= \frac{<f(x)f(x+t)> - <f(x)>^2}{<f^2(x)>-<f(x)>^2}
$$
\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{compare.png}
\caption{Tempo di autocorrelazione dell'energia con N=46.}
\end{figure}
Gli errori sono stati stimati ripetendo le misure (in questo grafico 12 volte).\\
Inoltre, il valore di $ t_{max} $ è stato scelto pari a 60 in quanto per valori superiori le oscillazioni intorno a zero delle funzioni di autocorrelazione per valori di temperatura più lontani dal punto critico sono troppo rumorose e invalidano il calcolo di $\tau_{corr}$ per quei valori di temperatura. Infatti aumentando $t_{max}$ gli errori associati aumentavano molto, anche per i punti più vicini al punto critico.\\ 
Come si può vedere dai grafici, l'algoritmo Metropolis ha un tempo di autocorrelazione nettamente più elevato rispetto a Swendsen-Wang. Questo diverso comportamento è dovuto principalmente al fatto che Metropolis è un algoritmo locale, ossia l'inversione di ogni spin dipende esclusivamente dagli spin circostanti ad esso. L'algoritmo di Swendsen-Wang invece, è non-locale a causa della taglia estesa  che i cluster possono assumere.
Questo permette a questo algoritmo di non avere difficoltà ad estrarre configurazioni statisticamente scorrelate più velocemente rispetto a Metropolis.\\

Non è stato possibile stimare il valore di $\tau_{corr}$ per l'algoritmo Metropolis attraverso un fit con una funzione del tipo $e^{-\frac{t}{\tau_{c}}}$ in quanto vicino al punto critico l'autocorrezione smette di avere l'andamento esponenziale che ha lontano dal punto critico.\\
Ciò non accade, invece, per l'algoritmo Swendsen-Wang siccome l'autocorrelazione tra le configurazioni rimane piccola anche al punto critico.
Per questo algoritmo è stato possibile calcolare il tempo di autocorrelazione attraverso un fit per una grande range di temperature.
L'osservabile di cui si è calcolato l'autocorrelazione è l'energia.
Gli errori nel grafico sono quelli generati dal fit dell'esponenziale.

\begin{figure}
\centering
	\includegraphics[scale=0.55]{sw/autocorrelazioneN150fit.png}
	\caption{Tempo di autocorrelazione con Swendsen-Wang tramite fit.}
\end{figure}
Il calcolo del tempo di autocorrelazione calcolato tramite fit concorda pienamente con l'altro metodo di calcolo.\\


\section{Binning}
Prima di affrontare la misura di osservabili è necessario analizzare come affrontare la correlazione fra le configurazioni estratte dagli algoritmi.
La tecnica migliore per ovviare a questo fatto è quella del \emph{binning}, ossia raggruppare misure in intervalli di larghezza abbastanza grande da diventare un gruppo di misure scorrelate tra loro.
A questo punto si procede a fare la media in ogni intervallo e si hanno così $\frac{N}{m}$ misure statisticamente indipendenti fra loro, a partire da $N$ misure autocorrelate suddivise in intervalli di larghezza $m$.\\
\'E fondamentale scegliere la larghezza corretta dell'intervallo. Ciò può essere fatto valutando l'andamento
della deviazione standard della media del nuovo set di $\frac{N}{m}$ misure in funzione di $m$.
Come si può immaginare, la larghezza del bin è associata al tempo di autocorellazione di cui si è parlato prima.

\subsection*{Metropolis}
Si vedano ora alcuni grafici di questa quantità a diverse temperature e per due diverse osservabili.
\begin{figure}[h!]
\subfigure[$\sigma$ Energia a $\beta=0.35$]{
	\includegraphics[scale=0.45]{metropolis/bin_en_035.png}
}
\subfigure[$\sigma$ Energia $\beta=0.435$]{
\includegraphics[scale=0.45]{metropolis/bin_en_043.png}
}
\caption{Metropolis}
\end{figure}
\begin{figure}[h!]
\subfigure[$\sigma$ Energia a $\beta=0.439$]{
	\includegraphics[scale=0.45]{metropolis/bin_en_0439.png}
}
\subfigure[$\sigma$ Energia $\beta=0.459$]{
\includegraphics[scale=0.45]{metropolis/bin_en_049.png}
}
\caption{Metropolis}
\end{figure}

\begin{figure}[h!]
\subfigure[$\sigma$ Magnetizzazione a $\beta=0.35$]{
	\includegraphics[scale=0.45]{metropolis/bin_mag_035.png}
}
\subfigure[$\sigma$ Magnetizzazione $\beta=0.43$]{
\includegraphics[scale=0.45]{metropolis/bin_mag_043.png}
}
\caption{Metropolis}
\end{figure}
\begin{figure}[h!]
\subfigure[$\sigma$ Magnetizzazione a $\beta=0.439$]{
	\includegraphics[scale=0.45]{metropolis/bin_mag_0439.png}
}
\subfigure[$\sigma$ Magnetizzazione $\beta=0.49$]{
\includegraphics[scale=0.45]{metropolis/bin_mag_049.png}
}
\caption{Metropolis}
\end{figure}

\newpage
\subsection*{Swendsen-Wang}
Si vedano anche per questo algoritmo le stesse osservabili alle stesse temperature di Metropolis. 
\begin{figure}[h!]
\subfigure[$\sigma$ Energia a $\beta=0.344$]{
	\includegraphics[scale=0.45]{sw/bin_en_0344.png}
}
\subfigure[$\sigma$ Energia $\beta=0.43$]{
\includegraphics[scale=0.45]{sw/bin_en_043.png}
}
\caption{Swendsen-Wang}
\end{figure}
\begin{figure}[h!]
\subfigure[$\sigma$ Energia a $\beta=0.44$]{
	\includegraphics[scale=0.45]{sw/bin_en_044.png}
}
\subfigure[$\sigma$ Energia $\beta=0.459$]{
\includegraphics[scale=0.45]{sw/bin_en_049.png}
}
\caption{Swendsen-Wang}
\end{figure}


\begin{figure}[h!]
\subfigure[$\sigma$ Magnetizzazione a $\beta=0.344$]{
	\includegraphics[scale=0.45]{sw/bin_mag_0344.png}
}
\subfigure[$\sigma$ Magnetizzazione $\beta=0.43$]{
\includegraphics[scale=0.45]{sw/bin_mag_043.png}
}
\caption{Swendsen-Wang}
\end{figure}
\begin{figure}[h!]
\subfigure[$\sigma$ Magnetizzazione a $\beta=0.44$]{
	\includegraphics[scale=0.45]{sw/bin_mag_044.png}
}
\subfigure[$\sigma$ Magnetizzazione $\beta=0.49$]{
\includegraphics[scale=0.45]{sw/bin_mag_049.png}
}
\caption{Swendsen-Wang}
\end{figure}

Come si può vedere da un confronto diretto dei grafici, analizzando il valore per cui la curva di appiattisce, si può notare che, come ci si poteva aspettare, nell'algoritmo Metropolis è necessario scegliere una larghezza dell'intervallo molto alta vicino al punto critico, addirittura un ordine di grandezza superiore rispetto a Swendsen-Wang.
Si stima la larghezza ottimale dell'intervallo cercando il punto in cui la curva si appiattisce o inizia ad avere una derivata prima molto più piccola rispetto ai punti iniziali.
Si può vedere inoltre, come avvicinandosi al punto critico sia necessario avere un intervallo più largo: ciò è una chiara conseguenza della crescita di $\tau_{corr}$ all'avvicinarsi al punto critico.\\
Inoltre, prendiamo l'esempio del caso metropolis. Alla temperatura $\beta = 0.325$ possiamo prendere come larghezza del bin 20. Poco sotto il punto critico, si ha come larghezza bin ~ 400/500.
Come si può immaginare, la larghezza del bin ottimale è strettamente dipendente dal tempo di autocorrelazione dell'osservabile.
Infine è stata scelta come larghezza dei bin per Metropolis 500 e per Swendsen-Wang 40.\\
Per via di questa grande differenza di larghezza dei bin il numero di passi temporali eseguiti con Metropolis è stato aumentato a 120000, mentre Swendsen-Wang rimane con 20000 passi in modo da avere errori più simili con i due algoritmi. In questo modo infatti si ha un numero di misure molto simile dopo il binning.\\
Nonostante Metropolis sia molto più veloce di Swendsen-Wang a parità di step temporali, la grande autocorrelazione fra le configurazioni generate impone di dover generare molte più configurazioni. Questo fatto lo rende più lento di Swendsen-Wang a generare un sample di dati simili.\\
Si confrontino i tempi dei due algoritmi in un reticolo 100x100:
\\
\begin{center}
\begin{tabular}{cc}
\toprule
	Metropolis (120000 step) & Swendsen-Wang (20000 step) \\
\midrule
	111 s & 48 s \\
\bottomrule
\end{tabular} 
\end{center}

L'algoritmo Swendsen-Wang risulta così più efficiente di Metropolis.
\newpage

\section{Energia e Magnetizzazione}
Energia e magnetizzazione sono le due principali osservabili di questo modello ed è possibile confrontare facilmente il loro andamento con la soluzione teorica di Onsager (valida però per un reticolo di taglia infinita).
Per la magnetizzazione è stata utilizzata l'osservabile \emph{improved} per Swendsen-Wang, ossia la frazione degli spin nel cluster più grande.
Nonostante i grafici siano stati fatti con un reticolo 100x100 l'accordo con la previsione teorica è eccellente per entrambe le osservabili e con entrambi gli algoritmi.
Insieme ai dati raccolti è stata sovrapposta la soluzione analitica di Onsager per entrambe le osservabili.
Gli errori sono stati calcolati attraverso il binning delle osservabili.
\begin{figure}[h]
	\subfigure[Metropolis]{
		\includegraphics[scale=0.35]{metropolis/en_beta.png}
	}
	\subfigure[Swendsen-Wang]{
		\includegraphics[scale=0.35]{sw/en_beta.png}
	}
\caption{Energia in funzione di $\beta$, 100x100.}
\end{figure}
Come si vede dai grafici, con entrambi gli algoritmi l'energia del sistema è perfettamente compatibile con la soluzione analitica già con un reticolo 100x100 e non si vedono differenze tra i due algoritmi.
\begin{figure}[h]
	\subfigure[Metropolis]{
		\includegraphics[scale=0.35]{metropolis/mag100.png}
	}
	\subfigure[Swendsen-Wang]{
		\includegraphics[scale=0.35]{sw/mag100.png}
	}
\caption{Magnetizzazione in funzione di $\beta$, 100x100.}

\end{figure}
\begin{center}
	\begin{figure}[h]
		\centering

		\includegraphics[scale=0.5]{sw/mag50100150.png}
		\caption{Magnetizzazione per L=50,75,100. Swendsen-Wang}
	\end{figure}
\end{center}

Diverso, invece, è il comportamento dei due algoritmi per la magnetizzazione. La differenza in questo caso è dovuto al fatto che per l'algoritmo Swendsen-Wang abbiamo utilizzato l'osservabile \emph{improved} ossia la frazione di siti nel cluster più grande.
Nella fase ferromagnetica i due risultati coincidono entrambi con la previsione teorica, mentre nella fase paramagnetica essi hanno un comportamento diverso fra di loro per il motivo appena spiegato, ma soprattutto diverso dalla soluzione teorica. \\
Ciò è da ricercare nella taglia finita del reticolo: infatti, per un sistema con un numero finito di gradi di libertà avremo che le osservabili sono sempre funzioni derivabili rispetto alla temperatura.
Solo nel limite termodinamico (e quindi con infiniti gradi di libertà) avremo osservabili non derivabili, come la magnetizzazione, e divergenti, come calore specifico e suscettività.
Per tutte queste osservabili per un numero finito di gradi di libertà avremo sempre funzioni lisce prive di divergenze, come si vedrà successivamente.\\
A sostegno di questa tesi si veda come all'aumentare della taglia del reticolo, la curva della magnetizzazione si avvicina sempre più a quella analitica, rimanendo sempre una funzione \emph{liscia}.

\section{Distribuzione di probabilità della magnetizzazione}

\begin{figure}[h]
\centering
	\subfigure[ $\beta=0.3$]{
		\includegraphics[scale=0.33]{metropolis/PDFM03.png}	
	}
	\subfigure[ $\beta=0.42$]{
		\includegraphics[scale=0.33]{metropolis/PDFM042.png}	
	}

	\caption{Metropolis}
\end{figure}
\begin{figure}[h]
\centering
		\subfigure[ $\beta=0.43$]{
		\includegraphics[scale=0.33]{metropolis/PDFM043.png}	
	}
	\subfigure[ $\beta=0.44$]{
		\includegraphics[scale=0.33]{metropolis/PDFM044.png}	
	}

	\caption{Metropolis}
\end{figure}

\begin{figure}[h]
\centering
		\subfigure[ $\beta=0.46$]{
		\includegraphics[scale=0.33]{metropolis/PDFM046.png}	
	}
	\subfigure[ $\beta=1$]{
		\includegraphics[scale=0.33]{metropolis/PDFM1.png}	
	}
	\caption{Metropolis}
\end{figure}

\begin{figure}[h]
\centering
	\subfigure[ $\beta=0.3$]{
		\includegraphics[scale=0.33]{sw/pdfM03.png}	
	}
	\subfigure[ $\beta=0.42$]{
		\includegraphics[scale=0.33]{sw/pdfM042.png}	
	}

	\caption{Swendsen-Wang}
\end{figure}
\begin{figure}[h]
\centering
		\subfigure[ $\beta=0.43$]{
		\includegraphics[scale=0.33]{sw/pdfM043.png}	
	}
	\subfigure[ $\beta=0.46$]{
		\includegraphics[scale=0.33]{sw/pdfM046.png}	
	}

	\caption{Swendsen-Wang}
\end{figure}

\begin{figure}[h]
\centering
	\subfigure[ $\beta=1$]{
		\includegraphics[scale=0.33]{sw/pdfM1.png}	
	}
	\subfigure[ $\beta=0.44$]{
		\includegraphics[scale=	0.33]{sw/pdfM044.png}	
	}
	\caption{Swendsen-Wang}
\end{figure}
Si studia ora la distribuzione di probabilità del modulo della magnetizzazione al variare della temperatura, confrontando fra loro i due algoritmi in questione.
Si è deciso di studiare il modulo della magnetizzazione in quanto l'algoritmo Swendsen-Wang ad ogni step inverte i cluster (con probabilità $\frac{1}{2}$), mentre Metropolis, siccome inverte uno spin alla volta, tende a mantere costante il segno della magnetizzazione per temperature sotto il punto critico.\\
I grafici sono stati calcolati per un reticolo 50x50.

Come si vede dai grafici, essi sono molto simili tra i due algoritmi e le leggere differenze che si notano sono da imputare al fatto che, anche in questo caso, per la magnetizzazione in Swendsen-Wang è stata utilizzata l'osservabile \emph{improved}.\\
Da questi istogrammi inoltre, si vede chiaramente come l'avvicinarsi al punto critico comporti un allargamento della larghezza della distribuzione. Questo è prevedibile in quanto, a meno di un fattore di volume, la varianza della magnetizzazione è la suscettività magnetica che ha un massimo (per un sistema finito) al punto critico.\\
A fronte di questo fatto, si può anche stimare che la temperatura critica per il reticolo 50x50 (quello utilizzato per gli istogrammi) è inferiore a $\beta=0.44$, dato che a questa temperatura la magnetizzazione è già più piccata che a $\beta=0.43$.


\newpage

\section{Lunghezza di correlazione}
\begin{figure}[h]
\centering
	\includegraphics[scale=0.5]{metropolis/cor120.png}
\caption{Lunghezza di correlazione $L=120$:Metropolis}
\end{figure}


La lunghezza di correlazione è stata stimata dal calcolo di:
$$
	<S_0 S_t > \, = \, A \, e^{-\frac{t}{\xi}} \qquad \mbox{dove} \qquad S_n = \frac{1}{L} \sum_i \sigma_{(n,i)} 
$$
Nel calcolo di $<S_0 S_t>$, inoltre è stata sfrutta l'invarianza per traslazione, rotazione di $\frac{\pi}{2}$ e inversione del reticolo, in modo da diminuire l'errore associato a questa grandezza.
Si sfrutta l'invarianza per traslazione calcolando più precisamente la seguente quantità:
$$
	<S_0 S_t> = \frac{1}{L} \sum <S_i S_{t+i}>
$$ 

\begin{figure}[h]
\centering
	\includegraphics[scale=0.5]{sw/corrN120.png}
\caption{Lunghezza di correlazione $L=120$:Swendsen-Wang}
\end{figure}
L'invarianza per rotazioni di $\frac{\pi}{2}$ è stata utilizzata mediando il calcolo fra righe e colonne. Inoltre è stata utilizzata anche l'invarianza per inversione  e la ciclicità del reticolo, le quali insieme comportano la validità di questa relazione:
$$
	< S_0 S_t> = < S_0 S_{L-t}>
$$
A questo punto si è calcolata osservabile e si sono stimati gli errori attraverso un binning come per le altre osservabili.
I Valori della lunghezza di correlazione sono poi così stati stimati fittando con un esponenziale decrescente. I valori ottenuti dal fit (errori compresi) sono stati utilizzati per i grafici della lunghezza di correlazione in funzione della temperatura.\\
A questo punto si è confrontata la dipendenza della lunghezza di correlazione $\xi$ con la previsione teorica, che prevede una divergenza (per un reticolo infinito) a potenza per temperature vicine a quella critica:
\begin{align*}
	\xi \sim t^{-\nu} \qquad \mbox{per} \; t \sim 0 \qquad \mbox{con} \; \nu = 1 \; \mbox{(teorico)}  \\
	t = \frac{\beta - \beta_{crit}}{\beta_{crit}} \qquad \beta_{crit} = 0.4406868
\end{align*}
per il valore di temperatura critica è stato utilizzato quello teorico
Gli estremi dell'intervallo in cui è stato fatto il fit sono stati scelti in modo che la correlazione rimanesse un ordine di grandezza inferiore al lato del reticolo, per evitare che la taglia finita del reticolo influenzasse la misura dell'esponente. Inoltre, si è cercato di rimanere quanto più possibile vicini al punto critico visto che l'equazione sopra citata vale nell'intorno del punto critico.\\
Dopo queste considerazioni è stato scelto come intervallo per il fit i valori $[0.415,0.43]$ per entrambi gli algoritmi. Il valore massimo di lunghezza di correlazione che si ottiene è $\sim 22$ che è piccolo rispetto al lato del reticolo pari a $120$. 
Il risultato del fit è quindi:
\begin{center}
	\begin{tabular}{cc}
	\toprule
	Algoritmo & $\nu$ \\
	\midrule
	Metropolis & $ 1.004 \pm 0.009 $\\
	Swendsen-Wang	& $ 1.018 \pm 0.005 $\\
	\bottomrule
	\end{tabular}
\end{center}

Con entrambi gli algoritmi si sono ottenuti risultati compatibili tra loro e abbastanza vicini alla previsione teorica.\\
Bisogna tenere in considerazione che la taglia finita del reticolo incide su molti aspetti relativi al calcolo dell'esponente critico. Primo fra tuttti non è possibili avvicinarsi troppo al punto critico perchè la taglia finita del reticolo modifica la divergenza (teorica) e la rende finita. Oltre a questo, la temperatura critica per un reticolo finito è leggermente più bassa di quella teorica che è stata utilizzata per effettuare il fit. 
\newpage
\section{Finite Size Scaling}
\subsubsection*{Calcolo suscettività e calore specifico}
Per il calcolo di queste due osservabili non è stato utilizzato il binning nello stesso modo usato per energia e magnetizzazione. Questo perchè sono definite utilizzando i valori medi di energia e magnetizzazione.\\
Per questo motivo sono stati creati degli intervalli di larghezza 3000 invece che 30 e sono state eseguite 30000 iterazioni dell'algoritmo, per diminuire l'errore.\\
La formula utilizzata è la seguente:
\begin{align*}
	c = \frac{1}{V} < \mathcal{H}^2>_{bin} - <\mathcal{H}>_{bin}^2 \\
	\chi = V < \mathcal{M}^2>_{bin} - <\mathcal{M}>_{bin}^2
\end{align*}
dove con $< ..>_{bin}$ si intende il valor medio sul bin di larghezza 3000 di cui si è parlato.

\subsection*{Stima di $\beta_{crit}$ e Finite Size Scaling }

Si andranno ora a fare uno studio di \emph{finite size scaling} per poter valutare l'accordo dei dati ottenuti per magnetizzazione, suscettività e calore specifico con gli esponenti critici esatti della soluzione di Onsager.
Per fare uno studio di \emph{finite size scaling} è necessario raccogliere dati sulle osservabili in esame per varie taglie del reticolo. In questo caso sono state utilizzati i seguenti reticoli:
\begin{itemize}
\item 35x35 
\item 50x50 
\item 65x65
\item 90x90
\item 120x120 
\item 150x150
\end{itemize}

A questo punto, per suscettività e calore specifico è stato necessario calcolare per ogni taglia del reticolo  la temperatura critica.\\
Si è deciso di stimare la temperatura critica facendo un fit con una parabola e stimando la temperatura critica come il massimo della parabola. Ciò ha dato risultati soddisfacenti nel caso della suscettività, mentre per il calore specifico il fit con la parabola non stimava correttamente la temperatura critica.
Per questo motivo, si è deciso di utilizzare la temperatura critica stimata attraverso la suscettività per ciascuna taglia del reticolo anche per il calore specifico. \\
Così facendo si è trascurata la dipendenza della temperatura critica dall'osservabile.
A posteriori si può vedere come questa assunzione sia giustificata vedendo il grafico dopo aver effettuato il finite size scaling per questa osservabile.\\
Le temperature critiche trovate in funzione della taglia del reticolo sono le seguenti:
\begin{center}
	\begin{tabular}{c c}
	\toprule
	Reticolo & $\beta_{crit}$ \\
	\midrule
	35x35 &  0.430294 \\ % 0.430437
	50x50 &  0.433357 \\ %0.433357
	65x65 & 0.435147 \\ %0.435147
	90x90 & 0.436540\\
	120x120 & 0.437669 \\ %0.437669
	150x150 & 0.438262 \\
	\end{tabular}
\end{center}
Per questo dato non è stato calcolato l'errore associato in quanto avrebbe richiesto ripetere varie volte le misure e siccome questa misura serve solo per poter effettuare il finite size scaling in modo corretto, il suo errore non influenza il risultato del finite size scaling.
Per la magnetizzazione questo non è stato necessario in quanto non presenta alcun picco.\\
Dopo aver ricavato la temperatura critica, si fa una traslazione sulla temperatura portandola nella nuova variabile 
$$
	 t = \frac{\beta - \beta_{crit}}{\beta_{crit}}
$$ 
Infine si effettua l'ultimo scaling, indicando con $L$ la taglia del reticolo e considerando la magnetizzazione si avrà:
\begin{align*}
	t \longrightarrow L^{\frac{1}{\nu}} t = L t \\
	M \longrightarrow \frac{M}{L^{\frac{-\beta}{\nu}}} = \frac{M}{L^{-\beta}}
\end{align*}
Per la suscettività si avrà:
$$
	\chi \longrightarrow \frac{\chi}{L^{\frac{\gamma}{\nu}}} = \frac{\chi}{L^{\gamma}}
$$
Nel caso del calore specifico, la soluzione analitica prevede che abbia esponente $\alpha=0$ il che indica uno scaling di tipo logaritmo. Per esso l'equazione precedente viene modificata in:
$$
	c \longrightarrow \frac{c}{\log{L}}
$$
Gli esponenti critici della soluzione analitica sono i seguenti:\\
\begin{center}
	\begin{tabular}{c c }
		\toprule
		Esponente & valore \\
		\midrule
		$\alpha$ & 0 \\
		$\beta$ & $1/8$\\
		$\gamma$ & $7/4$ \\
		\bottomrule
	\end{tabular}
\end{center}
Essi sono stati utilizzati per effettuare gli scaling delle varie osservabili.
\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.6]{sw/fssmag.png}
		\includegraphics[scale=0.6]{sw/fssmagzoom.png}
		\caption{Studio di Fss per $M= t^{\beta}$, con $\beta=\frac{1}{8}$}
	\end{figure}
\end{center}
\begin{figure}[h]
		\centering
		\includegraphics[scale=0.6]{sw/fsschi.png}
		\includegraphics[scale=0.6]{sw/fsschizoom.png}
		\caption{Studio di Fss per $\chi = t^{-\gamma}$, con $\gamma = \frac{7}{4}$}
\end{figure}

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.6]{sw/fsscv.png}
		\includegraphics[scale=0.6]{sw/fsscvzoom.png}
		\caption{Studio di Fss per $c = \log{ t} $ ( $\alpha=0$)}
	\end{figure}
\end{center}


A questo punto, ci si aspetta di vedere che le curve per ciascuna taglia, opportunamente scalate nella procedura descritta, collassino su un'unica curva \emph{universale}.
Come si può vedere dai grafici per queste tre osservabili è proprio ciò che accade nella regione paramagnetica con $\beta < \beta_{crit}$.\\
Siccome il \emph{finite size scaling} si basa sugli esponenti critici della soluzione esatta, dal risultato di questa analisi possiamo dire che le osservabili calcolate scalano in modo molto simile a ciò che ci si aspetterebbe teoricamente.
Per questo, gli esponenti critici del modello simulato sembrano risultare simili a quelli previsti teoricamente.

\newpage
\chapter{Modello di Potts}
Il modello di Potts è una generalizzazione del modello di Ising studiato nel capitolo precedente.
Esso generalizza il modello di Ising aggiungendo un numero arbitrario di stati.\\
 Si analizzerà ora il modello di Potts in 2 dimensioni con 3 stati. La sua implementazione ha sfruttato la rappresentazione degli stati come radici dell'unità $e^{2 \pi i}$ con $i=0,1,2$.
Il modello è stato implementato solo usando l'algoritmo Swendsen-Wang e verrà svolta un'analisi simile a quanto fatto con Ising data l'analogia tra i due modelli.


\section{Termalizzazione}

\begin{figure}[h!]
	\subfigure[$\beta=0.5$]{
		\includegraphics[scale=0.28]{potts/en_therm05.png}	
	}
	\subfigure[$\beta=1$]{
		\includegraphics[scale=0.28]{potts/en_therm1.png}	
	}
	\subfigure[$\beta=1.5$]{
		\includegraphics[scale=0.28]{potts/en_therm15.png}	
	}
	\caption{Andamento dell'energia in fase di termalizzazione}
\end{figure}

\begin{figure}[h!]
	\subfigure[$\beta=0.5$]{
		\includegraphics[scale=0.28]{potts/mag_therm05.png}	
	}
	\subfigure[$\beta=1$]{
		\includegraphics[scale=0.28]{potts/mag_therm1.png}	
	}
	\subfigure[$\beta=1.5$]{
		\includegraphics[scale=0.28]{potts/mag_therm15.png}	
	}
	\caption{Andamento della magnetizzazione in fase di termalizzazione}
\end{figure}
I siti del reticolo vengono inizializzati in modo uniformemente casuale tra i tre stati possibili.
Dopo aver analizzato l'andamento di energia e magnetizzazione nella fase di termalizzazione si è scelto di impostare un tempo di termalizzazione pari a 1000 passi temporali anche se come si può vedere dai grafici, già 100 passi sono sufficienti.

\section{Binning}
Il binning è stato implementato esattamente come nel modello di Ising. Siccome questo modello è stato simulato attraverso Swendsen-Wang ci si aspetta che la larghezza dei bin sia comparabile a quella nel modello di Ising con il medesimo algoritmo. Infatti così accade e anche in questo caso è stata scelta una larghezza degli intervalli pari a 40. Il numero totale di passi temporali dell'algoritmo è in questo caso di 10000, quindi si hanno circa la metà dei dati rispetto a Ising con Swendsen-Wang.\\
Si veda ora l'andamento della deviazione standar nel punto critico, temperatura in cui si ha l'autocorrelazione massima tra le configurazioni. A tutte le altre temperature, come nel modello di Ising, la curva si appiattisce molto più rapidamente.
\begin{center}
\begin{figure}[h!]
	\centering

 	\subfigure[ $\sigma$ della magnetizzazione]{
	\includegraphics[scale=0.4]{potts/mag_bincrit.png}
	}
 	\subfigure[ $\sigma$ dell'energia]{
	\includegraphics[scale=0.4]{potts/en_bincrit.png}
	}

\end{figure}
\end{center}

\section{Energia e Magnetizzazione}
A differenza del modello di Ising non si ha la soluzione analitica esatta di magnetizzazione ed energia in funzione della temperatura, quindi non è possibile confrontarle direttamente.\\
Si può vedere che la temperatura a cui avviene la transizione di fase è di poco sopra $\beta=1$ come previsto. I grafici sono stati fatti con un reticolo di taglia 100x100.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.55]{potts/en100.png}
	\caption{Energia per $L=100$}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.55]{potts/mag100.png}
	\caption{Magnetizzazione (improved) per $L=100$}
\end{figure}
Come nel caso del modello Ising, si possono apprezzare le differenze fra le diverse taglie del reticolo osservando la curva di magnetizzazione nella fase paramagnetica, dove le curve sono molto diverse tra loro, a differenza della fase ferromagnetica in cui questa differenza sparisce.\\
Le curve sono relative a reticoli 30x30, 75x75 e 150x150:

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{potts/mag_taglia.png}
\caption{Magnetizzazione per L=30,75,150.}
\end{figure}
\newpage
\section{Distribuzione di probabilità della magnetizzazione}
In questo modello, si può analizzare la distribuzione della probabilità della magnetizzazione nel piano complesso.
Ciò può essere fatto utilizzando la seguente definizione di magnetizzazione:
$$
	 M = \frac{| \sum_{siti} \phi_{i j} |}{N} 
$$
Se non si considera il modulo, essa può essere studiata nel piano complesso.\\
\begin{center}
\begin{figure}[h!]
\centering
 	\subfigure[$\beta=0.81$]{
	\includegraphics[scale=0.33]{potts/potts08.png}
	}
 	\subfigure[$\beta=0.9$]{
	\includegraphics[scale=0.33]{potts/potts09.png}
	}

 	\subfigure[$\beta=0.81$]{
	\includegraphics[scale=0.33]{potts/magmod081.png}
	}
 	\subfigure[$\beta=0.9$]{
	\includegraphics[scale=0.33]{potts/magmod09.png}
	}

\end{figure}
\end{center}
\begin{center}
\begin{figure}[h!]
\centering
 	\subfigure[$\beta=0.97$]{
	\includegraphics[scale=0.33]{potts/potts097.png}
	}
 	\subfigure[$\beta=0.99$]{
	\includegraphics[scale=0.33]{potts/potts099.png}
	}

 	\subfigure[$\beta=0.97$]{
	\includegraphics[scale=0.33]{potts/magmod097.png}
	}
 	\subfigure[$\beta=0.99$]{
	\includegraphics[scale=0.33]{potts/magmod099.png}
	}


\end{figure}
\end{center}


\begin{center}
\begin{figure}[h!]
\centering
	 	\subfigure[$\beta=1.005$]{
 	\includegraphics[scale=0.33]{potts/potts1005.png}
}
 	\subfigure[$\beta=1.015$]{
	\includegraphics[scale=0.33]{potts/potts1015.png}
	}
	 	\subfigure[$\beta=1.005$]{
 	\includegraphics[scale=0.33]{potts/magmod1005.png}
}
 	\subfigure[$\beta=1.015$]{
	\includegraphics[scale=0.33]{potts/magmod1015.png}
	}
\end{figure}
\end{center}


Come si vede dai grafici, quando si è vicini al punto critico e quindi la distribuzione di probabilità della magnetizzazione è molto larga, inizia ad emergere la figura di un triangolo che degenere nei 3 vertici superata la regione critica.\\
La comparsa di questi 3 punti è da imputare al tipo di algoritmo utilizzato per simulare questo modello, ossia Swendsen-Wang.
Ciò è infatti analogo a quanto accade al modello di Ising con il medesimo algoritmo se si studia la magnetizzazione senza aggiungere il modulo. Ciò è dovuto al fatto che ad ogni passo, per ogni cluster viene estratto un nuovo valore con probabilità $1/q$ dove $q$ è il numero di stati.\\
Per il modello di Potts con $q=4$, per esempio, otterremo i vertici di un quadrato e così via.


\newpage
\section{Lunghezza di correlazione}
Lo studio della lunghezza di correlazione è del tutto analago al modello di Ising.\\
La definizione dell'osservabile che permette di stimare la lunghezza di correlazione è diversa dal modello di ising:
$$
	Re(<S_0 S_t>) = A e^{-t \xi}
$$
Come nel modello di Ising è stata sfruttata l'invarianza per traslazioni, rotazioni e periodicità per diminuire l'errore associato a $<S_0 S_t>$.
Un altro commento necessario è relativo alla scelta dell'intervallo in cui fare il fit della lunghezza di correlazione.\\
Come nel caso di Ising, la temperatura più alta è scelta in modo che la lunghezza di correlazione sia molto minore rispetto alla taglia del reticolo, che in questo caso è 150x150. Anche in questo caso, l'estremo inferiore è stato scelto molto vicino al punto critico: l'intervallo è dunque il range di temperature $[0.95,0.995]$.
Anche in questo caso è stata utilizzata come valore di $\beta_{crit}$ quello teorico, ossia
$\beta_{crit} = log(1+\sqrt(3)) = 1.0050525..$
\begin{center}
\begin{figure}[h]
\centering
 	\includegraphics[scale=0.65]{potts/corr150.png}
 	\caption{Lunghezza di correlazione.}
\end{figure}
\end{center}

\begin{center}
\begin{tabular}{c c }

	\toprule
	metodo & valore \\
	\midrule
	teorico & $ 5/6 = 0.8333333 $ \\
	calcolato & $ 0.833 \pm 0.007 $\\

\end{tabular}

\end{center}


\newpage
\section{Finite Size Scaling}
Lo studio di finite size scaling per questo modello è del tutto analogo a quanto fatto con il modello di Ising, con l'unica differenza che gli esponenti critici sono diversi:
\begin{center}
	\begin{tabular}{c c}
	\toprule
	Esponente & valore \\
	\midrule
	$\alpha$ &  $1/3$ \\
	$\beta $ & $1/9$\\
	$\gamma$ & $13/9$ \\
	$\nu$ & $5/6$ \\
	\bottomrule
	\end{tabular}
\end{center}
L'unica grande differenza tra questi esponenti risiede nell'esponente critico $\alpha$, infatti per il modello di Ising si aveva $\alpha=0$ che indicava una scaling logaritmico mentre in questo modello si ha uno scaling a potenza anche per il calore specifico.
Per lo studio del finite size scaling sono stati utilizzati i seguenti reticoli:
\begin{itemize}
\item 35x35
\item 65x65
\item 90x90
\item 120x120
\item 150x150
\end{itemize}
La temperatura è stata stimata come nel modello di Ising, facendo un fit con una parabola della suscettività nell'intorno del punto critico. La temperatura critica trovata per un valore del lato del reticolo è stata poi utilizzata anche per il calore specifico. \\
Come si può vedere, all'aumentare del lato del reticolo la temperatura critica tende verso la temperatura critica teorica di cui si è parlato prima. \\
Non sono stati calcolati gli errori sulla temperatura critica in funzione del lato del reticolo in quanto questo calcolo è stato effettuato per migliorare i grafici di finite size scaling in modo che per ogni lato del reticolo le osservabili fossero centrate in zero.

\begin{center}
	\begin{tabular}{c c}
	\toprule
	Lato reticolo $(L)$ & $\beta_{crit}(L)$ \\
	\midrule
	35 & 0.992864 \\
	65 & 0.999176 \\
	90 &  1.001106 \\
	120 &  1.002264 \\
	150 & 1.003050\\
	\bottomrule
	\end{tabular}
\end{center}

\begin{center}
	\begin{figure}
	\centering
		\includegraphics[scale=0.55]{potts/magfss.png}
		\includegraphics[scale=0.55]{potts/magfsszoom.png}
		\caption{Studio di finite size scaling per magnetizzazione.}	
	\end{figure}
\end{center}


\begin{center}
	\begin{figure}
		\centering

		\includegraphics[scale=0.55]{potts/chifss.png}
				\includegraphics[scale=0.55]{potts/chifsszoom.png}

		\caption{Studio di finite size scaling per la suscettività.}	
	\end{figure}
\end{center}
\begin{center}
	\begin{figure}
		\centering

		\includegraphics[scale=0.55]{potts/cvfss.png}
				\includegraphics[scale=0.55]{potts/cvfsszoom.png}
		\caption{Studio di finite size scaling per il calore specifico.}	
	\end{figure}
\end{center}





\end{document}
